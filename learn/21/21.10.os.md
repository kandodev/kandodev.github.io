# OS Study
## Processes
Processes:
* An abstraction of a running program.
* Multiprogramming systems (can handle multiple processes). Pseudoparallelism (the illusion of parallel running) compared to true hardware parallelism in multiprocesser systems.
* Each process with it's own Program counter, registers, variables, etc -> flow of control. 
* Since the processor is switching programs, programs should not depend on exact timing.
* Processes that stay in the background to handle some activity are called daemons.
* New processes created by a new process system call from an already running process.
* In unix, only one system call: fork() to create processes. Allows the child to redirect std i/o/error before starting a program with execve.
* In Windows CreateProcess creates it and runs the program. Other function calls as well.
* Parent and child's address spaces are separate and don't share memory.     
* Processes can terminate voluntarily when they are done, when there's an error or a fatal error (divide by 0)
* One process can kill another if it has proper authorization.
* Process Heirarchies. In unix, a tree like structure. In windows, all are equal, though the parent does get a handle for it's child.
* A process may be in three states: Running, Ready (runnable, temporarily stopped to let another process run) and Blocked (unable to run until external event happens)
* A process scheduler (in the OS) handles the transitions from Ready to Running and vice versa. Scheduler handles interrupts and scheduling.
* Process table (an array of structures) contains all processes.
* Each entry contains info about process state (program counter, stack pointer, memory, etc.)
* Interrupt happens-> registers copied, etc. 

## Scheduling
### Scheduling
	* Selects which ready process to next have a crack at CPU time.
	* Processes spend time either doing computing or waiting for I/O:
	* Heavy computing processes are Compute-bound
	* Heavy I/O processes are I/O-bound
	* Non-preemptive scheduling: Let's a process run until it exits/errors out, or something else (possibly higher priority) interrupts. Goes back to the process after interrupt is dealt with.
	* Preemptive scheduling: Fixed max time after which it interrupts and chooses another process to run. Uses a clock interrupt, thus clock necessary.
	* Batch systems - Importance: Throughput (number of jobs completed per hour) and Turnaround Time (avg time for a job to complete from the moment it is submitted) ~ Usually non-preemptive
	* Interactive Systems - Importance: Minimizing response time. ~ Usually preemptive.
	* Real-time systems: - Like nuclear power plant. Must meet deadlines. ~ Can be either preemptive/Non. Because the processes know what they must do and are careful of other more important processes.
	
### Batch Scheduling
	* First come, first served:  when blocked process becomes ready, placed at the end of the queue. Adv: Easy to program, understand. Disadv: some jobs can make it run really slowly.
	* Shortest job first: non-preemptive ~ Provably optimal if all jobs are simultaneously available at the start. Reduces turnaround time.
	* Shortest Remaining time next: ~ Preemptive version of shortest job first
	
### Scheduling in Interactive Systems
	* Round Robin Scheduling: , time interval called quantum. After process uses it's quantum, put to the end of the list. Need to be careful about administrative overhead for small quantum numbers. Setting to too big causes poor response times for short jobs.
	* Priority Scheduling: Highest priority run first, scheduler may decrease priority of running process in set intervals to keep it from hogging cpu time. Or, each process can be assigned a max run time (regardless of priority). Can be assigned statically or dynamically. I/O bound process should get CPU time when they request it. An algorithm to set priority high for process that used the least amount of their assigned quantum will serve i/o bound processes well.
	* Multiple priority queues. High priority classes have less quantum assigned to them. When a process uses that up, it is moved down 1 class. 
	* Shortest process next: problem: figuring out which process is shortest. One approach is to make estimates based on previous behavior.
	* Guaranteed Scheduling: Guarantee at the start to the user how much allocation their process will have. Select process that has used the smallest ratio of their allocated time.
	* Lottery Scheduling: Randomized but more important processes can be given more "tickets". Cooperating processes may trade tickets.
	* Fair-share scheduling: Have each user, rather than the processes be allocated a fixed amount of CPU time. So one user can't hog resources with multiple processes.

### Real Time Scheduling
	* Very time sensitive. Some are hard real time, deadlines are a must. Some are soft real time: occasional deadline miss may happen.
	* Events may be periodic or aperiodic.
	* Schedulable if there is a way to meet deadlines.
	* Scheduler should include parameters that let the program decide which of it's children to allocate more time to.
	
### Thread Scheduling
	* Difference between user level threads and kernel level threads.
	* Scheduling between user level threads is faster and can be more efficient because it knows usually what the threads do, etc. However, no clock to interrupt a thread that has run too long. Another disadvantage is an i/o block on a thread blocks the whole process.
	* Switching between kernel level threads is slow (process switch sometimes) and it does not have a great idea of what each thread does, however it can interleave threads from multiple processes and this may be fast. Block does not suspend process.
	* Generally application level threads are faster.
